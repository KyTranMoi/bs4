{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết code thực hiện mô hình Retriever Generator bằng các thư viện Pytorch\n",
    "# Input: câu hỏi và 1 số file json chứa các đoạn văn\n",
    "# Output: các đoạn văn được sắp xếp theo độ liên quan với câu hỏi\n",
    "# Bước 1: Tạo các vector biểu diễn cho câu hỏi và các đoạn văn\n",
    "# Bước 2: Tính độ tương đồng giữa câu hỏi và các đoạn văn\n",
    "# Bước 3: Sắp xếp các đoạn văn theo độ tương đồng giảm dần\n",
    "# Bước 4: Trả về kết quả\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Khai báo các thư viện để thực hiện các yêu cầu trên\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bước 1: Tạo các vector biểu diễn cho câu hỏi và các đoạn văn\n",
    "# Hàm tạo vector biểu diễn cho câu hỏi\n",
    "# Input: câu hỏi\n",
    "# Output: vector biểu diễn cho câu hỏi\n",
    "def create_question_vector(question):\n",
    "    # Tách câu hỏi thành các từ\n",
    "    question_words = word_tokenize(question)\n",
    "    # Loại bỏ các từ không cần thiết\n",
    "    question_words = remove_stopwords(question_words)\n",
    "    # Chuẩn hóa các từ\n",
    "    question_words = normalize_words(question_words)\n",
    "    # Tạo vector biểu diễn cho câu hỏi\n",
    "    question_vector = create_vector_from_words(question_words)\n",
    "    return question_vector\n",
    "# Hàm tạo vector biểu diễn cho các đoạn văn\n",
    "# Input: đoạn văn\n",
    "# Output: vector biểu diễn cho đoạn văn\n",
    "def create_paragraph_vector(paragraph):\n",
    "    # Tách đoạn văn thành các từ\n",
    "    paragraph_words = word_tokenize(paragraph)\n",
    "    # Loại bỏ các từ không cần thiết\n",
    "    paragraph_words = remove_stopwords(paragraph_words)\n",
    "    # Chuẩn hóa các từ\n",
    "    paragraph_words = normalize_words(paragraph_words)\n",
    "    # Tạo vector biểu diễn cho đoạn văn\n",
    "    paragraph_vector = create_vector_from_words(paragraph_words)\n",
    "    return paragraph_vector\n",
    "# Hàm loại bỏ các từ không cần thiết\n",
    "# Input: danh sách các từ\n",
    "# Output: danh sách các từ sau khi loại bỏ các từ không cần thiết\n",
    "def remove_stopwords(words):\n",
    "    # Loại bỏ các từ không cần thiết\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if not word in stop_words]\n",
    "    return words\n",
    "# Hàm chuẩn hóa các từ\n",
    "# Input: danh sách các từ\n",
    "# Output: danh sách các từ sau khi chuẩn hóa\n",
    "def normalize_words(words):\n",
    "    # Chuẩn hóa các từ\n",
    "    ps = PorterStemmer()\n",
    "    words = [ps.stem(word) for word in words]\n",
    "    return words\n",
    "# Hàm tạo vector biểu diễn cho các từ\n",
    "# Input: danh sách các từ\n",
    "# Output: vector biểu diễn cho các từ\n",
    "def create_vector_from_words(words):\n",
    "    # Tạo vector biểu diễn cho các từ\n",
    "    vectors = []\n",
    "    for word in words:\n",
    "        vector = get_vector_from_word(word)\n",
    "        vectors.append(vector)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bước 2: Tính độ tương đồng giữa câu hỏi và các đoạn văn\n",
    "# Hàm tính độ tương đồng giữa câu hỏi và các đoạn văn\n",
    "# Input: câu hỏi, các đoạn văn\n",
    "# Output: danh sách các đoạn văn được sắp xếp theo độ tương đồng giảm dần\n",
    "def get_paragraphs_sorted_by_similarity(question, paragraphs):\n",
    "    # Tạo vector biểu diễn cho câu hỏi\n",
    "    question_vector = create_question_vector(question)\n",
    "    # Tạo vector biểu diễn cho các đoạn văn\n",
    "    paragraphs_vectors = []\n",
    "    for paragraph in paragraphs:\n",
    "        paragraph_vector = create_paragraph_vector(paragraph)\n",
    "        paragraphs_vectors.append(paragraph_vector)\n",
    "    # Tính độ tương đồng giữa câu hỏi và các đoạn văn\n",
    "    similarities = []\n",
    "    for paragraph_vector in paragraphs_vectors:\n",
    "        similarity = get_similarity(question_vector, paragraph_vector)\n",
    "        similarities.append(similarity)\n",
    "    # Sắp xếp các đoạn văn theo độ tương đồng giảm dần\n",
    "    paragraphs_sorted = [paragraph for _, paragraph in sorted(zip(similarities, paragraphs), reverse=True)]\n",
    "    return paragraphs_sorted\n",
    "# Hàm tính độ tương đồng giữa 2 vector\n",
    "# Input: 2 vector\n",
    "# Output: độ tương đồng giữa 2 vector\n",
    "def get_similarity(vector1, vector2):\n",
    "    # Tính độ tương đồng giữa 2 vector\n",
    "    similarity = np.dot(vector1, vector2)/(np.linalg.norm(vector1)*np.linalg.norm(vector2))\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bước 3: Sắp xếp các đoạn văn theo độ tương đồng giảm dần\n",
    "# Hàm sắp xếp các đoạn văn theo độ tương đồng giảm dần\n",
    "# Input: câu hỏi, các đoạn văn\n",
    "# Output: danh sách các đoạn văn được sắp xếp theo độ tương đồng giảm dần\n",
    "def get_paragraphs_sorted_by_similarity(question, paragraphs):\n",
    "    # Tạo vector biểu diễn cho câu hỏi\n",
    "    question_vector = create_question_vector(question)\n",
    "    # Tạo vector biểu diễn cho các đoạn văn\n",
    "    paragraphs_vectors = []\n",
    "    for paragraph in paragraphs:\n",
    "        paragraph_vector = create_paragraph_vector(paragraph)\n",
    "        paragraphs_vectors.append(paragraph_vector)\n",
    "    # Tính độ tương đồng giữa câu hỏi và các đoạn văn\n",
    "    similarities = []\n",
    "    for paragraph_vector in paragraphs_vectors:\n",
    "        similarity = get_similarity(question_vector, paragraph_vector)\n",
    "        similarities.append(similarity)\n",
    "    # Sắp xếp các đoạn văn theo độ tương đồng giảm dần\n",
    "    paragraphs_sorted = [paragraph for _, paragraph in sorted(zip(similarities, paragraphs), reverse=True)]\n",
    "    return paragraphs_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bước 4: Trả về kết quả\n",
    "# Hàm trả về kết quả\n",
    "# Input: câu hỏi, các đoạn văn\n",
    "# Output: kết quả\n",
    "def get_result(question, paragraphs):\n",
    "    # Sắp xếp các đoạn văn theo độ tương đồng giảm dần\n",
    "    paragraphs_sorted = get_paragraphs_sorted_by_similarity(question, paragraphs)\n",
    "    # Trả về kết quả\n",
    "    result = paragraphs_sorted[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MSI20\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'nttuan8_dl.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Hàm main và test\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m      3\u001b[0m     \u001b[39m# Đọc dữ liệu\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mnttuan8_dl.json\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m      5\u001b[0m     \u001b[39m# Lấy câu hỏi\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     question \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDeep Learning là gì ?\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nttuan8_dl.json'"
     ]
    }
   ],
   "source": [
    "# Hàm main và test\n",
    "if __name__ == '__main__':\n",
    "    # Đọc dữ liệu\n",
    "    data = json.load(open('nttuan8_dl.json', encoding='utf-8'))\n",
    "    # Lấy câu hỏi\n",
    "    question = \"Deep Learning là gì ?\"\n",
    "    # Lấy các đoạn văn từ 'content' của file json\n",
    "    paragraphs = [row['content'] for row in data]\n",
    "    # Trả về kết quả\n",
    "    result = get_result(question, paragraphs)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: farm-haystack in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.16.1)\n",
      "Requirement already satisfied: azure-ai-formrecognizer>=3.2.0b2 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (3.3.0b1)\n",
      "Requirement already satisfied: boilerpy3 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (1.0.6)\n",
      "Requirement already satisfied: canals in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (0.1.1)\n",
      "Requirement already satisfied: dill in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (0.3.6)\n",
      "Requirement already satisfied: events in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (0.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.5.0 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (0.14.1)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (4.17.3)\n",
      "Requirement already satisfied: mmh3 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (3.1.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (9.1.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (3.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (1.5.3)\n",
      "Requirement already satisfied: posthog in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (3.0.1)\n",
      "Requirement already satisfied: protobuf<=3.20.2 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (3.20.2)\n",
      "Requirement already satisfied: pydantic in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (1.10.7)\n",
      "Requirement already satisfied: quantulum3 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (0.8.1)\n",
      "Requirement already satisfied: rank-bm25 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (0.2.2)\n",
      "Requirement already satisfied: requests in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (2.28.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (1.2.2)\n",
      "Requirement already satisfied: sentence-transformers>=2.2.0 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (2.2.2)\n",
      "Requirement already satisfied: sseclient-py in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (1.7.2)\n",
      "Requirement already satisfied: tenacity in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.0 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (0.3.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (4.65.0)\n",
      "Requirement already satisfied: transformers[torch]==4.25.1 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from farm-haystack) (4.25.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]==4.25.1->farm-haystack) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]==4.25.1->farm-haystack) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hoain\\appdata\\roaming\\python\\python311\\site-packages (from transformers[torch]==4.25.1->farm-haystack) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]==4.25.1->farm-haystack) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]==4.25.1->farm-haystack) (2023.3.23)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]==4.25.1->farm-haystack) (0.13.3)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.7 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]==4.25.1->farm-haystack) (2.0.0)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.23.0 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack) (1.26.4)\n",
      "Requirement already satisfied: msrest>=0.6.21 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack) (0.7.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack) (1.1.28)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack) (4.5.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.5.0->farm-haystack) (2023.4.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=1.0.0->farm-haystack) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=1.0.0->farm-haystack) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=1.0.0->farm-haystack) (3.1.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers>=2.2.0->farm-haystack) (0.15.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers>=2.2.0->farm-haystack) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers>=2.2.0->farm-haystack) (0.1.99)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->farm-haystack) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->farm-haystack) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->farm-haystack) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->farm-haystack) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\hoain\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->farm-haystack) (0.4.6)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema->farm-haystack) (22.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema->farm-haystack) (0.19.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hoain\\appdata\\roaming\\python\\python311\\site-packages (from pandas->farm-haystack) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->farm-haystack) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hoain\\appdata\\roaming\\python\\python311\\site-packages (from posthog->farm-haystack) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from posthog->farm-haystack) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from posthog->farm-haystack) (2.2.1)\n",
      "Requirement already satisfied: inflect in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from quantulum3->farm-haystack) (6.0.4)\n",
      "Requirement already satisfied: num2words in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from quantulum3->farm-haystack) (0.5.12)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack) (0.6.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack) (1.3.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch!=1.12.0,>=1.7->transformers[torch]==4.25.1->farm-haystack) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch!=1.12.0,>=1.7->transformers[torch]==4.25.1->farm-haystack) (3.1.2)\n",
      "Requirement already satisfied: click in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->sentence-transformers>=2.2.0->farm-haystack) (8.1.3)\n",
      "Requirement already satisfied: docopt>=0.6.2 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from num2words->quantulum3->farm-haystack) (0.6.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision->sentence-transformers>=2.2.0->farm-haystack) (9.4.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack) (3.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch!=1.12.0,>=1.7->transformers[torch]==4.25.1->farm-haystack) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hoain\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch!=1.12.0,>=1.7->transformers[torch]==4.25.1->farm-haystack) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U farm-haystack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'haystack.document_store'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhaystack\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdocument_store\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmemory\u001b[39;00m \u001b[39mimport\u001b[39;00m InMemoryDocumentStore\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhaystack\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mretriever\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdense\u001b[39;00m \u001b[39mimport\u001b[39;00m DensePassageRetriever\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhaystack\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m convert_files_to_dicts\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'haystack.document_store'"
     ]
    }
   ],
   "source": [
    "from haystack.document_store.memory import InMemoryDocumentStore\n",
    "from haystack.retriever.dense import DensePassageRetriever\n",
    "from haystack.preprocessor.utils import convert_files_to_dicts\n",
    "from haystack.preprocessor.cleaning import clean_wiki_text\n",
    "from haystack.pipeline import Pipeline\n",
    "\n",
    "# Tạo InMemoryDocumentStore\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "# Load các file json chứa các đoạn vănz\n",
    "file_paths = [\"file1.json\", \"file2.json\", \"file3.json\"]\n",
    "docs = convert_files_to_dicts(file_paths)\n",
    "\n",
    "# Xóa các ký tự không cần thiết trong các đoạn văn\n",
    "for doc in docs:\n",
    "    doc[\"text\"] = clean_wiki_text(doc[\"text\"])\n",
    "\n",
    "# Lưu các đoạn văn vào InMemoryDocumentStore\n",
    "document_store.write_documents(docs)\n",
    "\n",
    "# Tạo DensePassageRetriever để tìm kiếm các đoạn văn phù hợp với câu hỏi\n",
    "retriever = DensePassageRetriever(document_store=document_store,\n",
    "                                 query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "                                 passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "                                 use_gpu=False,\n",
    "                                 embed_title=True,\n",
    "                                 max_seq_len=256,\n",
    "                                 batch_size=16)\n",
    "\n",
    "# Tạo Pipeline để thực hiện các bước tiền xử lý và truy xuất\n",
    "pipe = Pipeline()\n",
    "pipe.add_node(component=retriever, name=\"Retriever\", inputs=[\"Query\"])\n",
    "pipe.add_node(component=retriever, name=\"Generator\", inputs=[\"Retriever\"])\n",
    "\n",
    "# Định nghĩa câu hỏi và chạy Pipeline\n",
    "question = \"What is the capital of France?\"\n",
    "result = pipe.run(query=question)\n",
    "\n",
    "# Lấy kết quả trả về\n",
    "answers = result[\"Generator\"]\n",
    "for ans in answers:\n",
    "    print(ans[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(75.96726989746094,\n",
       "  'Nội dung\\nDeep learning là gì?\\nÝ tưởng và mục đích của loạt bài viết này.\\nSách Deep Learning cơ bản\\nKhóa Deep Learning cơ bản\\nNội dung của loạt bài viết\\nMôi trường\\nYêu cầu\\nDeep learning là gì?\\nTrong khoảng vài năm trở lại đây mọi người được nghe rất nhiều về cách mạng công nghiệp 4.0. Vậy điều gì đã làm lên sự đặc biệt? Hạt nhân cho sự bùng nổ đến từ Artificial Intelligence (trí tuệ nhân tạo) hay cụ thể là Machine Learning (máy học). Ứng dụng của AI thì ở khắp mọi nơi như là: ô tô tự lái; robot phẫu thuật; hệ thống dịch tự động; chatbot tự động trả lời; AlphaGo,…\\nMachine learning theo định nghĩa của wiki, “Machine learning is the subfield of computer science that “gives computers the ability to learn without being explicitly programmed “, ý là chương trình có thể tự học được từ dữ liệu.\\nMachine learning là một ngành rất rộng và nặng về toán, gồm rất nhiều thuật toán và mỗi thuật toán có ứng dụng riêng tùy vào bài toán:\\nLinear Regression\\nLogistic Regresstion\\nDecision Tree and Random Forest\\nNaive Bayes\\nSupport Vector Machines\\nK-Nearest Neighbors\\nPrincipal component analysis (PCA)\\n…\\nNeural network\\nDeep learning được bắt nguồn từ thuật toán Neural network, chỉ là một ngành nhỏ của machine learning nhưng nó giống như con gà để trứng vàng vậy.\\nSource: Nvidia\\nNhững ứng dụng mà được kể ở trên đều có được nhờ áp dụng deep learning. Cùng với khả năng tính toán vượt trội của máy tính và lượng dữ liệu khổng lồ mà con người tạo ra, deep learning đang có những bước đột phá thực sự.\\nÝ tưởng và mục đích của loạt bài viết này.\\nGần đây mình có tìm hiểu về ứng dụng của Deep learning trong y học. Mình nhận thấy là mình biết về Deep Learning (DL) nhưng không có kiến thức về y học nên không biết được là nó có thể ứng dụng như thế nào trong y học vì người thực sự có kiến thức về y học là bác sĩ chứ không phải mình. Bác sĩ thì gặp vấn đề ngược lại là không có kiến thức về Deep Learning.\\nThế nên mình quyết định viết loạt bài viết này để giới thiệu các kiến thức cơ bản về Deep Learning cũng như các ứng dụng của nó để mọi người có kiến thức chuyên môn, có dữ liệu trong các ngành khác như y tế, ngân hàng nông nghiệp,… có thể tự áp dụng được Deep learning trong lĩnh vực của họ.\\nLoạt bài cũng rất phù hợp cho những người mới bắt đầu muốn tìm hiểu về AI, ML, Deep Learning cũng như các bạn học công nghệ thông tin hoặc chuyên ngành toán muốn chuyển ngành qua.\\nCuối cùng, hy vọng qua loạt bài viết này mọi người có được những kiến thức cơ bản về deep learning và thấy được các ứng dụng của nó. Để rồi áp dụng các ý tưởng vào start-up, công ty để có các ứng dụng hay, thiết thực cho xã hội.\\nSách Deep Learning cơ bản\\nSách Deep Learning cơ bản được tổng hợp từ series này. Tuy nhiên nội dung sách được biên soạn cẩn thận hơn so với blog ở các phần sau:\\nHướng dẫn cài đặt và sử dụng môi trường Anaconda cũng như google colab cho người mới dùng dễ sử dụng hơn.\\nKiến thức về Python cơ bản.\\nPhần bài tập sau mỗi chương để bạn đọc vận dụng các kiến thức đã học.\\nNội dung mỗi bài được chỉnh sửa cẩn thận hơn.\\nMọi người tải sách ở đây.\\nKhóa Deep Learning cơ bản\\nBên cạnh đó mình cũng mở khóa Deep Learning cơ bản dành cho các bạn có kiến thức cơ bản về toán cao cấp và lập trình, muốn học tập và theo đuổi con đường ML/DL/AI.\\nNội dung của loạt bài viết\\nBài 1: Linear regression và gradient descent\\nBài 2: Logistic regression\\nBài 3: Neural network\\nBài 4: Backpropagation\\nBài 5: Giới thiệu về xử lý ảnh\\nBài 6: Convolutional neural network\\nBài 7: Giới thiệu keras và bài toán phân loại ảnh\\nBài 8: Ứng dụng CNN cho ô tô tự lái\\nBài 9: Transfer learning và data augmentation\\nBài 10: Các kĩ thuật cơ bản trong deep learning\\nBài 11: Object detection với faster-RCNN\\nBài 12: Image segmentation với U-Net\\nBài 13: Recurrent neural network\\nBài 14: Long-short term memory\\nBài 15: Ứng dụng thêm mô tả cho ảnh (image captioning)\\nMôi trường\\nTất cả code trong loạt bài viết bằng python, thư viện cho deep learning mình dùng keras. Mình khuyên các bạn nên dùng Google colab (link hướng dẫn sử dụng) vì bạn không cần cài đặt trên máy mà có thể chạy code được luôn hoặc cài Anaconda (link hướng dẫn cài đặt) và dùng phần mềm spyder hoặc jupyter notebook.\\nYêu cầu\\nKiến thức về toán cơ bản cấp ba: hàm số, đạo hàm.\\nKiến thức cơ bản về lập trình: biến, vòng lặp. Nếu bạn hoàn toàn chưa biết gì về lập trình, xem qua loạt bài viết này bài 2, 3, 5, 9, 10, 11 để có kiến thức cơ bản về Python trước khi bắt đầu bài 1.\\nÝ thức học hỏi kiến thức mới.\\nVì loạt bài viết này mình muốn viết cho tất cả mọi người nên mình sẽ giải thích tất cả mọi thứ chi tiết nhất có thể. Mọi người có thắc mắc, không hiểu thì cứ chủ động hỏi ở phần bình luận, nếu không phải mình thì mình tin là sẽ có những người khác giúp đỡ bạn.\\nFacebook cá nhân của mình.\\nFanpage trên Facebook.\\nGroup trên Facebook.\\nCảm ơn mọi người rất nhiều.\\nTAGS: Deep LearningMachine Learning'),\n",
       " (74.37983703613281,\n",
       "  'Bài trước đã giới thiệu về convolutional neural network (CNN) cho bài toán với input là ảnh. Bài này sẽ giới thiệu về thư viện keras và ứng dụng keras để xây dựng mô hình CNN cho bài toán phân loại ảnh.\\nNội dung\\nGiới thiệu về keras\\nMNIST Dataset\\nXây dựng bài toán\\nChuẩn bị dữ liệu\\nXây dựng model\\nLoss function\\nỨng dụng keras cho MNIST dataset\\nỨng dụng của việc phân loại ảnh\\nGiới thiệu về keras\\nBản chất của bài toán Deep learning: Bạn có dữ liệu, bạn muốn máy tính học được các mô hình (model) từ dữ liệu, sau đó dùng mô hình đấy để dự đoán được các dữ liệu mới. Các bước cơ bản làm một bài toán deep learning :\\nXây dựng bài toán\\nChuẩn bị dữ liệu (dataset)\\nXây dựng model\\nĐịnh nghĩa loss function\\nThực hiện backpropagation và áp dụng gradient descent để tìm các parameter gồm weight và bias để tối ưu loss function.\\nDự đoán dữ liệu mới bằng model với các hệ số tìm được ở trên\\nBước xây dựng model thì áp dụng các kiến thức được trình bày trong bài neural network và convolutional neural network ta có thể xây dựng model hoàn chỉnh từ đầu bằng python. Tuy nhiên bước backpropagation trở nên phức tạp hơn rất rất nhiều. Khó để implement và tối ưu được tốc độ tính toán. Đấy là lý do các framework về deep learning ra đời với các đặc điểm:\\nNgười dùng chỉ cần định nghĩa model và loss function, framework sẽ lo phần backpropagation.\\nViệc định nghĩa layer, activation function, loss function đơn giản hơn cho người dùng. Ví dụ để thêm layer trong neural network chỉ cần báo là layer có bao nhiêu node và dùng hàm activation gì.\\nTối ưu việc tính toán trên CPU và GPU.\\nCác deep learning framework phổ biến. Nguồn:\\nhttps://towardsdatascience.com/deep-learning-framework-power-scores-2018-23607ddf297a\\nCó thể thấy tensorflow là framework phổ biến nhất tuy nhiên tensorflow khá khó sử dụng cho người mới bắt đầu. Nên mình sẽ giới thiệu về keras: dễ sử dụng, thân thiện với người dùng nhưng đủ tốt để làm các bài toán về deep learning.\\nKeras là một framework mã nguồn mở cho deep learning được viết bằng Python. Nó có thể chạy trên nền của các deep learning framework khác như: tensorflow, theano, CNTK. Với các API bậc cao, dễ sử dụng, dễ mở rộng, keras giúp người dùng xây dựng các deep learning model một cách đơn giản.\\nMNIST Dataset\\nXây dựng bài toán\\nBạn có ảnh xám kích thước 28*28 của chữ số từ 1 đến 9 và bạn muốn dự đoán số đấy là số mấy. Ví dụ:\\nDữ liệu đầu tiên trong MNIST dataset.\\nChuẩn bị dữ liệu\\nMNIST là bộ cơ sở dữ liệu về chữ số viết tay, bao gồm 2 tập con: training set gồm 60.000 ảnh các chữ số viết tay và test set gồm 10.000 ảnh các chữ số.\\nTraining set, test set là gì?\\nGiả sử bạn đang luyện thi đại học và bạn có 10 bộ đề để luyện thi. Nếu bạn học và chữa cả 10 đề một cách chi tiết thì bạn sẽ không thể ước lượng được điểm thi của bạn khoảng bao nhiêu, dẫn đến bạn không chọn được trường phù hợp. Thế là bạn nghĩ ra một giải pháp tốt hơn, trong 10 đề đấy chỉ lấy 8 đề học và chữa chi tiết thôi còn để 2 đề lại coi như là đề thi thật. Như vậy bạn có thể ước lượng điểm thi của mình bằng cách đánh giá điểm ở 2 đề đấy.\\nTrong ví dụ trên thì:\\n8 đề ôn luyện được gọi là training set, có thể hiểu là dữ liệu dùng để dạy cho model học.\\n2 đề để rành gọi là validation set, là để đánh giá xem model hiện tại có tốt không, thường được dùng để chỉnh các tham số của model.\\nđề thi đại học thật là test set, là để đánh giá xem model hoạt động với dữ liệu thực tế có tốt không.\\nNhư vậy MNIST dataset có 60.000 dữ liệu ở training set ở trong MNIST, ta sẽ chia ra 50.000 dữ liệu cho training set và 10.000 dữ liệu cho validation set. Vẫn giữ nguyên 10.000 dữ liệu của test set.\\nXây dựng model\\nVì input của model là ảnh nên nghĩ ngay đến convolutional neural network (CNN).\\nMô hình chung bài toán CNN: Input image -> Convolutional layer (Conv) + Pooling layer (Pool) -> Fully connected layer (FC) -> Output.\\nModel cho bài toán\\nInput của model là ảnh xám kích thước 28*28.\\nSoftmax function\\nGiống như bài logistic regression, thay vì chỉ muốn kết quả là ảnh là số mấy, ta muốn dự đoán phần trăm của ảnh là số nào. Ví dụ: 90% ảnh là số 5, 1% ảnh là số 1,…\\nNhắc lại bài neural network, ở mỗi layer sẽ thực hiện 2 bước: tính tổng linear các node ở layer trước và thực hiện activation function (ví dụ sigmoid function, softmax function). Do sau bước tính tổng linear cho ra các giá trị thực nên cần dùng softmax function dùng để chuyển đổi giá trị thực trong các node ở output layer sang giá trị phần trăm.\\nVì mỗi ảnh sẽ thuộc 1 class từ 0 đến 9, nên tất cả sẽ có 10 class. Nên output layer sẽ có 10 node để tương ứng với phần trăm ảnh là số 0,1,..,9. Ví dụ:\\na\\n6\\nlà xác xuất ảnh là số 5. (Sự khác biệt chỉ số do các số bắt đầu từ 0 trong khi chỉ số của node trong layer bắt đầu từ 1)\\nSoftmax function\\n\\nTổng quát sau hàm activation:\\na\\nk\\n=\\n∑\\ni=1\\n10\\ne\\nz\\ni\\ne\\nz\\nk\\n.\\nNhận xét:\\ni=1\\n∑\\n10\\na\\ni\\n=1\\n0<a\\ni\\n<1\\nDo đó ta có thể coi\\na\\ni\\nlà xác xuất ảnh là số (i-1).\\nVới các bài toán classification (phân loại) thì nếu có 2 lớp thì hàm activation ở output layer là hàm sigmoid, còn nhiều hơn 2 lớp thì hàm activation ở ouput layer là hàm softmax\\n=> Output layer có 10 nodes và activation là softmax function.\\nLoss function\\nĐể định nghĩa loss function, trước hết ta dùng one-hot encoding chuyển đổi label của ảnh từ giá trị số sang vector cùng kích thước với output của model. Ví dụ:\\nĐể ý là label của data là số i là vector v kích thước 10*1 với\\nv\\ni+1\\n=1 và các giá trị khác bằng 0. So với quy ước về phần trăm ở trên thì one-hot encoding có ý nghĩa là ta chắc chắn 100% ảnh này là số 5.\\nGiờ ta có giá trị thật (label) dạng one-hot encoding giá trị dự đoán ở output layer sau hàm softmax function cùng kích thước 10*1. Ta cần định nghĩa hàm loss function để đánh giá độ tốt của model.\\nMong muốn là\\na\\n6\\ngần 1 còn các giá trị a khác gần 0 vì như thế nghĩa là model dự đoán đúng được ảnh đầu vào là ảnh số 5. Ta định nghĩa loss function:\\nL=−\\ni=1\\n∑\\n10\\ny\\ni\\n∗log(\\ny\\ni\\n^\\n)\\nThử đánh giá hàm L. Giả sử ảnh là số 5 thì\\nL=−log(\\ny\\n6\\n^\\n).\\nNhận xét:\\nHàm L giảm dần từ 0 đến 1\\nKhi model dự đoán\\ny\\n6\\n^\\ngần 1, tức giá trị dự đoán gần với giá trị thật\\ny\\n6\\nthì L nhỏ, xấp xỉ 0\\nKhi model dự đoán\\ny\\n6\\n^\\ngần 0, tức giá trị dự đoán ngược lại giá trị thật\\ny\\n6\\nthì L rất lớn\\n=> Hàm L nhỏ khi giá trị model dự đoán gần với giá trị thật và rất lớn khi model dự đoán sai, hay nói cách khác L càng nhỏ thì model dự đoán càng gần với giá trị thật. => Bài toán tìm model trở thành tìm giá trị nhỏ nhất của L.\\nHàm loss function định nghĩa như trên trong keras gọi là “categorical_crossentropy“\\nỨng dụng keras cho MNIST dataset\\nCode mọi người lấy ở đây và có thể dùng google colab (không cần cài đặt trên máy và có thể dùng được luôn) để chạy code với hướng dẫn sử dụng ở đây.\\nViewer requires iframe.\\nview raw\\nmnist.ipynb hosted with ❤ by GitHub\\nỨng dụng của việc phân loại ảnh\\nChuẩn đoán ảnh X-ray của bệnh nhân có bị ung thư hay không\\nPhân loại, nhận diện được các chữ, số viết tay => tự động đọc được biển số xe, văn bản.\\nPhân loại được các biển báo giao thông => hỗ trợ cho ô tô tự lái\\n…\\nMọi người có thể luyện tập tự xây dựng model cho CIFAR10 dataset bao gồm 50,000 training set và 10.000 test set ảnh màu kích thước 32×32 cho 10 thể loại khác nhau (máy bay, ô tô, thuyền, chim, chó, mèo, ngựa,…).\\n# Load dữ liệu cifar10\\nfrom keras.datasets import cifar10\\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\\nBài 8: Ứng dụng CNN cho ô tô tự lái\\nBài 6: Convolutional neural network\\nTAGS: Giới Thiệu Về KerasImage ClassificationKerasMnist DatasetPhân Loại Ảnh'),\n",
       " (73.56446838378906,\n",
       "  'Deep learning có 2 mô hình lớn là Convolutional Neural Network (CNN) cho bài toán có input là ảnh và Recurrent neural network (RNN) cho bài toán dữ liệu dạng chuỗi (sequence). Mình đã giới thiệu về Convolutional Neural Network (CNN) và các ứng dụng của deep learning trong computer vision bao gồm: classification, object detection, segmentation. Có thể nói là tương đối đầy đủ các dạng bài toán liên quan đến CNN. Bài này mình sẽ giới thiệu về RNN.\\nNội dung\\nRecurrent Neural Network là gì?\\nDữ liệu dạng sequence\\nPhân loại bài toán RNN\\nỨng dụng bài toán RNN\\nMô hình bài toán RNN\\nMô hình RNN\\nLoss function\\nBackpropagation Through Time (BPTT)\\nRecurrent Neural Network là gì?\\nBài toán: Cần phân loại hành động của người trong video, input là video 30s, output là phân loại hành động, ví dụ: đứng, ngồi, chạy, đánh nhau, bắn súng,…\\nKhi xử lý video ta hay gặp khái niệm FPS (frame per second) tức là bao nhiêu frame (ảnh) mỗi giây. Ví dụ 1 FPS với video 30s tức là lấy ra từ video 30 ảnh, mỗi giây một ảnh để xử lý.\\nTa dùng 1 FPS cho video input ở bài toán trên, tức là lấy ra 30 ảnh từ video, ảnh 1 ở giây 1, ảnh 2 ở giây 2,… ảnh 30 ở giây 30. Bây giờ input là 30 ảnh: ảnh 1, ảnh 2,… ảnh 30 và output là phân loại hành động. Nhận xét:\\nCác ảnh có thứ tự ví dụ ảnh 1 xẩy ra trước ảnh 2, ảnh 2 xẩy ra trước ảnh 3,… Nếu ta đảo lộn các ảnh thì có thể thay đổi nội dung của video. Ví dụ: nội dung video là cảnh bắn nhau, thứ tự đúng là A bắn trúng người B và B chết, nếu ta đảo thứ tự ảnh thành người B chết xong A mới bắn thì rõ ràng bây giờ A không phải là kẻ giết người => nội dung video bị thay đổi.\\nTa có thể dùng CNN để phân loại 1 ảnh trong 30 ảnh trên, nhưng rõ ràng là 1 ảnh không thể mô tả được nội dung của cả video. Ví dụ: Cảnh người cướp điện thoại, nếu ta chỉ dùng 1 ảnh là người đấy cầm điện thoại lúc cướp xong thì ta không thể biết được cả hành động cướp.\\n=> Cần một mô hình mới có thể giải quyết được bài toán với input là sequence (chuỗi ảnh 1->30) => RNN ra đời.\\nDữ liệu dạng sequence\\nDữ liệu có thứ tự như các ảnh tách từ video ở trên được gọi là sequence, time-series data.\\nTrong bài toán dự đoán đột quỵ tim cho bệnh nhân bằng các dữ liệu tim mạch khám trước đó. Input là dữ liệu của những lần khám trước đó, ví dụ i1 là lần khám tháng 1, i2 là lần khám tháng 2,… i8 là lần khám tháng 8. (i1,i2,..i8) được gọi là sequence data. RNN sẽ học từ input và dự đoán xem bệnh nhân có bị đột quy tim hay không.\\nVí dụ khác là trong bài toán dịch tự động với input là 1 câu, ví dụ “tôi yêu Việt Nam” thì vị trí các từ và sự xắp xếp cực kì quan trọng đến nghĩa của câu và dữ liệu input các từ [‘tôi’, ‘yêu’, ‘việt’, ‘nam’] được gọi là sequence data. Trong bài toán xử lý ngôn ngữ (NLP) thì không thể xử lý cả câu được và người ta tách ra từng từ làm input, giống như trong video người ta tách ra các ảnh (frame) làm input.\\nPhân loại bài toán RNN\\nCác dạng bài toán RNN\\nOne to one: mẫu bài toán cho Neural Network (NN) và Convolutional Neural Network (CNN), 1 input và 1 output, ví dụ với CNN input là ảnh và output là ảnh được segment.\\nOne to many: bài toán có 1 input nhưng nhiều output, ví dụ: bài toán caption cho ảnh, input là 1 ảnh nhưng output là nhiều chữ mô tả cho ảnh đấy, dưới dạng một câu.\\nNguồn: https://towardsdatascience.com/image-captioning-in-deep-learning-9cd23fb4d8d2\\nMany to one: bài toán có nhiều input nhưng chỉ có 1 output, ví dụ bài toán phân loại hành động trong video, input là nhiều ảnh (frame) tách ra từ video, ouptut là hành động trong video\\nMany to many: bài toán có nhiều input và nhiều output, ví dụ bài toán dịch từ tiếng anh sang tiếng việt, input là 1 câu gồm nhiều chữ: “I love Vietnam” và output cũng là 1 câu gồm nhiều chữ “Tôi yêu Việt Nam”.\\nỨng dụng bài toán RNN\\nVề cơ bản nếu bạn thấy sequence data hay time-series data và bạn muốn áp dụng deep learning thì bạn nghĩ ngay đến RNN. Dưới đây là một số ứng dụng của RNN:\\nSpeech to text: Chuyển giọng nói sang text.\\nSentiment classification: phân loại số sao cho các bình luận, ví dụ: input: “ứng dụng tốt”, output: 4 sao.\\nMachine translation: Bài toán dịch tự động giữa các ngôn ngữ.\\nVideo recognition: Nhận diện hành động trong video.\\nHeart attack: Dự đoán đột quỵ tim.\\n….\\nMô hình bài toán RNN\\nMô hình RNN\\nBài toán: Nhận diện hành động trong video 30s. Đây là dạng bài toán many to one trong RNN, tức nhiều input và 1 output.\\nInput ta sẽ tách video thành 30 ảnh ở mỗi giây. Các ảnh sẽ được cho qua model CNN để lấy ra các feature (feature extraction) thành các vector có kích thước n*1. Vector tương ứng với ảnh ở giây thứ i là\\nx\\ni\\n.\\nOutput là vector có kích thước d*1, softmax function được sử dụng như trong bài phân loại ảnh.\\nMô hình RNN cho bài toán.\\nTa có:\\nMô hình có 30 input và 1 output, các input được cho vào model đúng với thứ tự ảnh trong video\\nx\\n1\\n,x\\n2\\n,...x\\n30\\n.\\nMỗi hình tròn được gọi là 1 state, state t có input là\\nx\\nt\\nvà\\ns\\nt−1\\n(output của state trước); output là\\ns\\nt\\n=f(U∗x\\nt\\n+W∗s\\nt−1\\n). f là activation function thường là tanh hoặc ReLU.\\nCó thể thấy\\ns\\nt\\nmang cả thông tin từ state trước (\\ns\\nt−1\\n) và input của state hiện tại =>\\ns\\nt\\ngiống như memory nhớ các đặc điểm của các input từ\\nx\\n1\\nđến\\nx\\nt\\ns\\n0\\nđược thêm vào chỉ cho chuẩn công thức nên thường được gán bằng 0 hoặc giá trị ngẫu nhiên. Có thể hiểu là ban đầu chưa có dữ liệu gì để học thì memory rỗng.\\nDo ta chỉ có 1 output, nên sẽ được đặt ở state cuối cùng, khi đó\\ns\\n30\\nhọc được thông tin từ tất cả các input.\\ny\\n^\\n=g(V∗s\\n30\\n). g là activation function, trong bài này là bài toán phân loại nên sẽ dùng softmax.\\nTa thấy là ở mỗi state các hệ số W, U là giống nhau nên model có thể được viết lại thành:\\nMô hình RNN rút gọn\\nTóm lại:\\nx\\ni\\nlà vector có kích thước n*1,\\ns\\ni\\nlà vector có kích thước m*1,\\ny\\ni\\nlà vector có kích thước d*1. U là ma trận có kích thước m*n, W là ma trận có kích thước m*m và V là ma trận có kích thước d*m.\\ns\\n0\\n=0,s\\nt\\n=f(U∗x\\nt\\n+W∗s\\nt−1\\n) với t >= 1\\ny\\n^\\n=g(V∗s\\n30\\n)\\nLoss function\\nLoss function của cả mô hình bằng tổng loss của mỗi output, tuy nhiên ở mô hình trên chỉ có 1 output và là bài toán phân loại nên categorical cross entropy loss sẽ được sử dụng.\\nLoss function\\nBackpropagation Through Time (BPTT)\\nCó 3 tham số ta cần phải tìm là W, U, V. Để thực hiện gradient descent, ta cần tính:\\n∂U\\n∂L\\n,\\n∂V\\n∂L\\n,\\n∂W\\n∂L\\n.\\nTính đạo hàm với V thì khá đơn giản:\\n∂V\\n∂L\\n=\\n∂\\ny\\n^\\n∂L\\n∗\\n∂V\\n∂\\ny\\n^\\nTuy nhiên với U, W thì lại khác.\\n∂W\\n∂L\\n=\\n∂\\ny\\n^\\n∂L\\n∗\\n∂s\\n30\\n∂\\ny\\n^\\n∗\\n∂W\\n∂s\\n30\\nDo\\ns\\n30\\n=f(W∗s\\n29\\n+V∗x\\n30\\n) có\\ns\\n29\\nphụ thuộc vào W. Nên áp dụng công thức hồi cấp 3 bạn học:\\n(f(x)∗g(x))\\n′\\n=f\\n′\\n(x)∗g(x)+f(x)∗g\\n′\\n(x). Ta có\\n∂W\\n∂s\\n30\\n=\\n∂W\\n∂s\\n30\\n′\\n+\\n∂s\\n29\\n∂s\\n30\\n∗\\n∂W\\n∂s\\n29\\n, trong đó\\n∂W\\n∂s\\n30\\n′\\nlà đạo hàm của\\ns\\n30\\nvới W khi coi\\ns\\n29\\nlà constant với W.\\nTương tự trong biểu thức\\ns\\n29\\ncó\\ns\\n28\\nphụ thuộc vào W,\\ns\\n28\\ncó\\ns\\n27\\nphụ thuộc vào W … nên áp dụng công thức trên và chain rule:\\n∂W\\n∂L\\n=\\ni=0\\n∑\\n30\\n∂\\ny\\n^\\n∂L\\n∗\\n∂s\\n30\\n∂\\ny\\n^\\n∗\\n∂s\\ni\\n∂s\\n30\\n∗\\n∂W\\n∂s\\ni\\n′\\n, trong đó\\n∂s\\ni\\n∂s\\n30\\n=\\nj=i\\n∏\\n29\\n∂s\\nj\\n∂s\\nj+1\\nvà\\n∂W\\n∂s\\ni\\n′\\nlà đạo hàm của\\ns\\ni\\nvới W khi coi\\ns\\ni−1\\nlà constant với W.\\nNhìn vào công thức tính đạo hàm của L với W ở trên ta có thể thấy hiện tượng vanishing gradient ở các state đầu nên ta cần mô hình tốt hơn để giảm hiện tượng vaninshing gradient => Long short term memory (LSTM) ra đời và sẽ được giới thiệu ở bài sau. Vì trong bài toán thực tế liên quan đến time-series data thì LSTM được sử dụng phổ biến hơn là mô hình RNN thuần nên bài này không có code, bài sau sẽ có code ứng dụng với LSTM.\\nBài 14: Long short term memory\\nBài 12: Image segmentation với U-net\\nTAGS: Deep LearningRecurrent Neural Netwrk'),\n",
       " (73.17096710205078,\n",
       "  'Nội dung\\nÝ tưởng và mục đích\\nNội dung của loạt bài viết\\nYêu cầu\\nỨng dụng của GAN\\nGenerate Photographs of Human Faces\\nImage editing\\nGenerate Anime characters\\nGenerate Realistic Photographs\\nImage-to-Image Translation\\nUnsupervised Image-to-image translation\\nSuper-resolution\\nText to image\\nGenerate new human pose\\nMusic generation\\nÝ tưởng và mục đích\\nSau sự thành công của series Deep Learning cơ bản cũng như sách Deep Learning cơ bản, mình tiếp tục muốn giới thiệu tới bạn đọc series về GAN, một nhánh nhỏ trong Deep Learning nhưng đang rất phát triển. Nó như một hướng đi tiếp theo cho những ai đã theo hết series Deep Learning cơ bản.\\nMô hình GAN được giới thiệu bởi Ian J. Goodfellow vào năm 2014 và đã đạt được rất nhiều thành công lớn trong Deep Learning nói riêng và AI nói chung. Yann LeCun, VP and Chief AI Scientist, Facebook, từng mô tả về GAN: “The most interesting idea in the last 10 years in Machine Learning”. Để mọi người thấy được các ứng dụng của GAN, phần dưới mình sẽ trình bày một vài ứng dụng điển hình của GAN.\\nMình không thích phong cách mì ăn liền nên ở mỗi bài mình sẽ bám theo paper giải thích đủ toán cho mọi người một cách đơn giản và dễ hiểu nhất có thể. Bên cạnh đó sau mỗi bài mình sẽ hướng dẫn đọc code, là luôn có ứng dụng thực tế đi kèm. Series Deep Learning cơ bản giống như cung cấp nền tảng về Deep Learning cho mọi người, còn series này muốn giúp mọi người làm quen với việc đọc paper, đọc code trên github và chạy với custom dataset.\\nQua đó hy vọng mọi người dễ tiếp cận hơn với việc nghiên cứu trong môi trường học thuật cũng như đi làm ở công ty về lĩnh vực Machine Learning hay Deep Learning.\\nNội dung của loạt bài viết\\nBài 1: Giới thiệu về GAN\\nBài 2: Deep Convolutional Generative Adversarial Network (DCGAN)\\nBài 3: Conditional GAN (cGAN)\\nBài 4: Least Squares Generative Adversarial Networks (LSGAN)\\nBài 5: GAN evaluation\\nBài 6: Image to image translation\\nBài 7: Pix2pix\\nBài 8: CycleGAN\\nBài 9: StarGAN\\n*Nội dung của series có thể bị thay đổi trong quá trình viết.\\nYêu cầu\\nVì đây series tiếp theo của loạt bài về Deep Learning cơ bản nên mọi người cần có kiến thức cơ bản về Deep Learning, hoặc đã theo hết các bài 1, 2, 3, 5, 6, 7, 10 từ series Deep Learning cơ bản (tất nhiên đã học hết cả series thì càng tốt).\\nỨng dụng của GAN\\nGenerate Photographs of Human Faces\\nVí dụ về ảnh mặt người do GAN sinh ra từ 2014 đến 2017. Mọi người có thể thấy chất lượng ảnh sinh ra tốt lên đáng kể theo thời gian.\\nẢnh mặt GAN sinh ra qua các năm ,Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation, 2018.\\nHình dưới là ảnh sinh ra bởi GAN năm 2018, phải để ý rất chi tiết thì mới có thể phân biệt được ảnh mặt đấy là sinh ra hay ảnh thật.\\nStyleGAN\\nImage editing\\nChắc mọi người vẫn nhớ tới FaceApp làm mưa làm gió trong thời gian vừa qua. Nó là một ứng dụng của GAN để sửa các thuộc tính vào khuôn mặt như màu tóc, da, giới tính, cảm xúc hay độ tuổi.\\nStargan\\nAge-cGAN\\nGenerate Anime characters\\nViệc thuê các họa sĩ thiết kế các nhân vật anime rất đắt đỏ thế nên GAN được sử dụng để tự động sinh ra các nhân vật anime.\\nTowards the Automatic Anime Characters Creation with Generative Adversarial Networks\\nGenerate Realistic Photographs\\nNăm 2018, Andrew Brock cho ra paper “Large Scale GAN Training for High Fidelity Natural Image Synthesis” với BigGAN có khả năng sinh ra các ảnh tự nhiên rất khó phân biệt với ảnh chụp thường.\\nExample of Realistic Synthetic Photographs Generated with BigGANTaken from Large Scale GAN Training for High Fidelity Natural Image Synthesis, 2018.\\nImage-to-Image Translation\\nVí dụ điển hình của mô hình Image to image translation là Pix2pix. Input là 1 ảnh và output là 1 ảnh tương ứng, ví dụ input là ảnh không màu, output là ảnh màu. Mọi người có thể vào đây thử, input là bản phác (draft) con mèo, output là ảnh con mèo hay input là các khối block, output là ảnh ngôi nhà.\\nVí dụ ảnh draft sang ảnh màu, taken from Image-to-Image Translation with Conditional Adversarial Networks, 2016.\\nUnsupervised Image-to-image translation\\nBài toán trên (Image-to-image translation) là supervised tức là ta có các dữ liệu thành cặp (input, output) như bản phác thảo của cái cặp và ảnh màu của nó. Tuy nhiên khi muốn chuyển dữ liệu từ domain này sang domain khác (từ ngựa thường sang ngựa vằn) thì ta không có sẵn các cặp dữ liệu để train đó gọi là bài toán unsupervised.\\nCycleGAN\\nSuper-resolution\\nGAN có thể dùng để tăng chất lượng của ảnh từ độ phân giải thấp lên độ phân giải cao với kết quả rất tốt.\\nSRGAN\\nText to image\\nGAN có thể học sinh ra ảnh với input là một câu.\\nStackGAN\\nGenerate new human pose\\nVới ảnh người đứng và dáng đứng mới, GAN có thể sinh ra người với dáng đứng mới.\\nPose Guided Person Image Generation\\nMusic generation\\nNgoài các ứng dụng với ảnh, GAN có thể áp dụng để sinh ra những bản nhạc.\\nMidiNet\\nTAGS: GANGenerative Adversarial Networks'),\n",
       " (73.16397094726562,\n",
       "  'Ở những bài trước mình đã giới thiệu về mô hình Recurrent Neural Network (RNN) cho bài toán dữ liệu dạng chuỗi. Tuy nhiên RNN chỉ có short term memory và bị vanishing gradient. Tiếp đó mình đã giới thiệu về Long short term memory (LSTM) có cả short term memory và long term memory, hơn thế nữa tránh được vaninishing gradient. Bài này mình sẽ viết về ứng dụng của LSTM cho ứng dụng image captioning.\\nBài viết được tham khảo từ đây.\\nNội dung\\nỨng dụng\\nDataset\\nPhân tích bài toán\\nCác bước chi tiết\\nImage embedding với Inception\\nText preprocessing\\nWord embedding\\nOutput\\nModel\\nCode\\nỨng dụng\\nVí dụ image captioning. Nguồn: https://towardsdatascience.com/image-captioning-in-deep-learning-9cd23fb4d8d2\\nTa có thể thấy ngay 2 ứng dụng của image captioning:\\nĐể giúp những người già mắt kém hoặc người mù có thể biết được cảnh vật xung quanh hay hỗ trợ việc di chuyển. Quy trình sẽ là: Image -> text -> voice.\\nGiúp google search có thể tìm kiếm được hình ảnh dựa vào caption.\\nDataset\\nDữ liệu dùng trong bài này là Flickr8k Dataset. Mọi người tải ở đây. Dữ liệu gồm 8000 ảnh, 6000 ảnh cho traning set, 1000 cho dev set (validation set) và 1000 ảnh cho test set.\\nBạn tải về có 2 folder: Flicker8k_Dataset và Flicker8k_Text. Flicker8k_Dataset chứa các ảnh với tên là các id khác nhau. Flicker8k_Text chứa:\\nFlickr_8k.testImages, Flickr_8k.devImages, Flickr_8k.trainImages, Flickr_8k.devImages chứa id các ảnh dùng cho việc test, train, validation.\\nFlickr8k.token chứa các caption của ảnh, mỗi ảnh chứa 5 captions\\nVí dụ ảnh dưới có 5 captions:\\nA child in a pink dress is climbing up a set of stairs in an entry way.\\nA girl going into a wooden building .\\nA little girl climbing into a wooden playhouse .\\nA little girl climbing the stairs to her playhouse .\\nA little girl in a pink dress going into a wooden cabin .\\nẢnh trong Flickr8k dataset\\nThực ra 1 ảnh nhiều caption cũng hợp lý vì bức ảnh có thể được mô tả theo nhiều cách khác nhau. Một ảnh 5 caption sẽ cho ra 5 traning set khác nhau: (ảnh, caption 1), (ảnh, caption 2), (ảnh, caption 3), (ảnh, caption 4), (ảnh, caption 5). Như vậy traning set sẽ có 6000 * 5 =40000 dataset.\\nPhân tích bài toán\\nInput là ảnh và output là text, ví dụ “man in black shirt is playing guitar”.\\nNhìn chung các mô hình machine learning hay deep learning đều không xử lý trực tiếp với text như ‘man’, ‘in’, ‘black’,… mà thường phải quy đổi (encode) về dạng số. Từng từ sẽ được encode sang dạng vector với độ dài số định, phương pháp đấy gọi là word embedding. Để hiểu rõ hơn về word embedding mọi người xem thêm ở đây (bài tiếng việt giải thích rất chi tiết).\\nNhìn thấy output là text nghĩ ngay đến RNN và sử dụng mô hình LSTM.\\nInput là ảnh thường được extract feature qua pre-trained model với dataset lớn như ImageNet và model phổ biến như VGG16, ResNet, quá trình được gọi là embedding và output là 1 vector.\\nÝ tưởng sẽ là dùng embedding của ảnh và dùng các từ phía trước để dự đoán từ tiếp theo trong caption.\\nVí dụ:\\nEmbedding vector + A -> girl\\nEmbedding vector + A girl -> going\\nEmbedding vector + A girl going -> into\\nEmbedding vector + A girl going into -> a.\\nEmbedding vector + A girl going into a -> wooden building .\\nEmbedding vector + A girl going into a wooden -> building .\\nMô hình của bài toán\\nĐể dự đoán từ tiếp theo ta sẽ xây dựng từ điển các từ xuất hiện trong training set (ví dụ 2000 từ) và bài toán trở thành bài toán phân loại từ, xem từ tiếp theo là từ nào, khá giống như bài phân loại ảnh.\\nCác bước chi tiết\\nImage embedding với Inception\\nCó lẽ cái tên GoogLeNet sẽ quen thuộc hơn và gặp nhiều hơn so với Inception, GoogLeNet là version 1 của Inception, hiện giờ mô hình phổ biến là Inception v3.\\nMô hình Googlenet, Going Deeper with Convolutions, Szegedy et al\\nThay vì trong mỗi Conv layer chỉ dùng 1 kernel size nhất định như 3*3, 5*5, thì giờ ở một layer có nhiều kernel size khác nhau, do đó mô hình có thể học được nhiều thuộc tính khác nhau của ảnh trong mỗi layer.\\nCụ thể hơn mọi người xem thêm ở đây.\\nTa sẽ sử dụng pre-trained model Inception v3 với dataset Imagenet. Do là pre-trained model yêu cầu ảnh đầu vào là 229*229 nên ra sẽ resize ảnh về kích thước này. Sau khi qua pre-trained model ta sẽ lấy được embedding vector của ảnh, kích thước 256*1\\nText preprocessing\\nTa xử lý text qua một số bước cơ bản.\\nChuyển chữ hoa thành chữ thường, “Hello” -> “hello”\\nBỏ các kí tự đặc biệt như “%”, “$”, “#”\\nLoại bỏ các chữ có số như hey199\\nSau đó ta sẽ thêm 2 từ “startseq” và “endseq” để biểu thị sự bắt đầu và kết thúc của caption. Ví dụ: “startseq a girl going into a wooden building endseq“. “endseq” dùng khi test ảnh thì biết kết thúc của caption.\\nTa thấy có 8763 chữ khác nhau trong số 40000 caption. Tuy nhiên ta không quan tâm lắm những từ mà chỉ xuất hiện 1 vài lần, vì nó giống như là nhiễu vậy và không tốt cho việc học và dự đoán từ của model, nên ta chỉ giữ lại những từ mà xuất hiện trên 10 lần trong số tất cả các caption. Sau khi bỏ những từ xuất hiện ít hơn 10 lần ta còn 1651 từ.\\nTuy nhiên do độ dài các sequence khác nhau, ví dụ: “A”, ” A girl going”, ” A girl going into a wooden”, nên ta cần padding thêm để các chuỗi có cùng độ dài bằng với độ dài của chuỗi dài nhất là 34. Do đó số tổng số từ (từ điển) ta có là 1651 + 1 (từ dùng để padding).\\nWord embedding\\nPre-trained GLOVE Model được sử dụng cho quá trình word embedding.\\nMọi người vào link này để tải file glove.6B.zip\\nTừng dòng trong file sẽ lưu text và encoded vector khích thước 200*1\\nOutput\\nBài toán là dự đoán từ tiếp theo trong chuỗi ở input với ảnh hiện tại, nên output là từ nào trong số 1652 từ trong từ điển mà ta có. Với bài toán phân loại thì softmax activation và categorical_crossentropy loss function được sử dụng.\\nModel\\nLayer (type)                    Output Shape         Param #     Connected to                     \\n==================================================================================================\\ninput_3 (InputLayer)            (None, 34)           0                                            \\n__________________________________________________________________________________________________\\ninput_2 (InputLayer)            (None, 2048)         0                                            \\n__________________________________________________________________________________________________\\nembedding_1 (Embedding)         (None, 34, 200)      330400      input_3[0][0]                    \\n__________________________________________________________________________________________________\\ndropout_1 (Dropout)             (None, 2048)         0           input_2[0][0]                    \\n__________________________________________________________________________________________________\\ndropout_2 (Dropout)             (None, 34, 200)      0           embedding_1[0][0]                \\n__________________________________________________________________________________________________\\ndense_1 (Dense)                 (None, 256)          524544      dropout_1[0][0]                  \\n__________________________________________________________________________________________________\\nlstm_1 (LSTM)                   (None, 256)          467968      dropout_2[0][0]                  \\n__________________________________________________________________________________________________\\nadd_1 (Add)                     (None, 256)          0           dense_1[0][0]                    \\n                                                                 lstm_1[0][0]                     \\n__________________________________________________________________________________________________\\ndense_2 (Dense)                 (None, 256)          65792       add_1[0][0]                      \\n__________________________________________________________________________________________________\\ndense_3 (Dense)                 (None, 1652)         424564      dense_2[0][0]                    \\n==================================================================================================\\nTotal params: 1,813,268\\nTrainable params: 1,813,268\\nNon-trainable params: 0\\nCode\\nViewer requires iframe.\\nview raw\\nAutomatic Image Captioning.ipynb hosted with ❤ by GitHub\\nBài 14: Long short term memory (LSTM)\\nTAGS: Deep LearningImage CaptioningLSTMRNN')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# load the json file\n",
    "with open(\"data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# load the pretrained retriever model and tokenizer\n",
    "model_name = \"facebook/dpr-question_encoder-single-nq-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# define a function to retrieve relevant documents for\n",
    "def retrieve_documents(question, k):\n",
    "    # encode the question into tokens and convert to tensor\n",
    "    question_input = tokenizer(question, return_tensors=\"pt\", truncation=True, max_length=256)\n",
    "    # get the embedding vector of the question from the model\n",
    "    question_embed = model(**question_input).pooler_output # shape: (1, embed_size)\n",
    "\n",
    "    # initialize an empty list to store the pairs of (similarity, document)\n",
    "    results = []\n",
    "\n",
    "    # loop through the elements in the json file\n",
    "    for item in data:\n",
    "        # get the content value as the document\n",
    "        document = item.get(\"content\")\n",
    "\n",
    "        # encode the document into tokens and convert to tensor\n",
    "        document_input = tokenizer(document, return_tensors=\"pt\", truncation=True, max_length=256)\n",
    "\n",
    "        # get the embedding vector of the document from the model\n",
    "        document_embed = model(**document_input).pooler_output # shape: (1, embed_size)\n",
    "\n",
    "        # compute the similarity between the question and document embeddings using dot product or cosine similarity\n",
    "        similarity = torch.dot(question_embed.squeeze(), document_embed.squeeze()) # or torch.cosine_similarity(question_embed, document_embed)\n",
    "\n",
    "        # append the pair of (similarity, document) to the results list\n",
    "        results.append((similarity.item(), document))\n",
    "    # sort the results list by descending order of similarity\n",
    "    results.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # get the top k pairs of (similarity, document)\n",
    "    results = results[:k]\n",
    "\n",
    "    # return the results list as the output\n",
    "    return results\n",
    "\n",
    "retrieve_documents(\"Giới thiệu về Deep learning ?\", 5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
